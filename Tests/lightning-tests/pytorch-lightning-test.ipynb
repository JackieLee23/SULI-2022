{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389e3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9398c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Don't have to worry about:\n",
    "#Setting model to training/eval\n",
    "#Using device for gpu support and pushing model to device\n",
    "#Optimizer zero grad\n",
    "#Calling backwards function or optimizer step\n",
    "#Can have automatic learning rate setter\n",
    "#Can run test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0f3e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5c245bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitNeuralNet(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LitNeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        \n",
    "        #log to tensorboard\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        \n",
    "        #log to tensorboard\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91e8d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", \n",
    "    train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "    batch_size=batch_size, num_workers=4, shuffle=False)\n",
    "\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(root=\"./data\", \n",
    "    train=False, transform=transforms.ToTensor())\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "    batch_size=batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a fast_dev_run\n",
    "model = LitNeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "trainer = pl.Trainer(fast_dev_run = True)\n",
    "trainer.fit(model, train_dataloaders=train_loader, \n",
    "            val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b2a9db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | l1   | Linear | 392 K \n",
      "1 | relu | ReLU   | 0     \n",
      "2 | l2   | Linear | 5.0 K \n",
      "--------------------------------\n",
      "397 K     Trainable params\n",
      "0         Non-trainable params\n",
      "397 K     Total params\n",
      "1.590     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  86%|███████████████████▋   | 600/700 [00:04<00:00, 128.88it/s, loss=0.111, v_num=8]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                    | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  86%|███████████████████▋   | 601/700 [00:04<00:00, 125.68it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  86%|███████████████████▊   | 602/700 [00:04<00:00, 125.76it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  86%|███████████████████▊   | 603/700 [00:04<00:00, 125.81it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  86%|███████████████████▊   | 604/700 [00:04<00:00, 125.82it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  86%|███████████████████▉   | 605/700 [00:04<00:00, 125.92it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  87%|███████████████████▉   | 606/700 [00:04<00:00, 126.02it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  87%|███████████████████▉   | 607/700 [00:04<00:00, 126.11it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  87%|███████████████████▉   | 608/700 [00:04<00:00, 126.19it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  87%|████████████████████   | 609/700 [00:04<00:00, 126.28it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  87%|████████████████████   | 610/700 [00:04<00:00, 126.35it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  87%|████████████████████   | 611/700 [00:04<00:00, 126.42it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  87%|████████████████████   | 612/700 [00:04<00:00, 126.51it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  88%|████████████████████▏  | 613/700 [00:04<00:00, 126.59it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  88%|████████████████████▏  | 614/700 [00:04<00:00, 126.67it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  88%|████████████████████▏  | 615/700 [00:04<00:00, 126.72it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  88%|████████████████████▏  | 616/700 [00:04<00:00, 126.80it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  88%|████████████████████▎  | 617/700 [00:04<00:00, 126.89it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  88%|████████████████████▎  | 618/700 [00:04<00:00, 126.93it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  88%|████████████████████▎  | 619/700 [00:04<00:00, 127.02it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  20%|█████▊                       | 20/100 [00:00<00:00, 191.89it/s]\u001b[A\n",
      "Epoch 0:  89%|████████████████████▎  | 620/700 [00:04<00:00, 127.07it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  89%|████████████████████▍  | 621/700 [00:04<00:00, 127.13it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  89%|████████████████████▍  | 622/700 [00:04<00:00, 127.22it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  89%|████████████████████▍  | 623/700 [00:04<00:00, 127.32it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  89%|████████████████████▌  | 624/700 [00:04<00:00, 127.41it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  89%|████████████████████▌  | 625/700 [00:04<00:00, 127.50it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  89%|████████████████████▌  | 626/700 [00:04<00:00, 127.59it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  90%|████████████████████▌  | 627/700 [00:04<00:00, 127.67it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  90%|████████████████████▋  | 628/700 [00:04<00:00, 127.78it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  90%|████████████████████▋  | 629/700 [00:04<00:00, 127.87it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  90%|████████████████████▋  | 630/700 [00:04<00:00, 127.95it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  90%|████████████████████▋  | 631/700 [00:04<00:00, 128.04it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  90%|████████████████████▊  | 632/700 [00:04<00:00, 128.13it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  90%|████████████████████▊  | 633/700 [00:04<00:00, 128.22it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  91%|████████████████████▊  | 634/700 [00:04<00:00, 128.29it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  91%|████████████████████▊  | 635/700 [00:04<00:00, 128.29it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  91%|████████████████████▉  | 636/700 [00:04<00:00, 128.35it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  91%|████████████████████▉  | 637/700 [00:04<00:00, 128.42it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  91%|████████████████████▉  | 638/700 [00:04<00:00, 128.49it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  91%|████████████████████▉  | 639/700 [00:04<00:00, 128.41it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████████▌                 | 40/100 [00:00<00:00, 193.07it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████  | 640/700 [00:04<00:00, 128.42it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████  | 641/700 [00:04<00:00, 128.47it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████  | 642/700 [00:04<00:00, 128.53it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████▏ | 643/700 [00:04<00:00, 128.61it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████▏ | 644/700 [00:05<00:00, 128.66it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████▏ | 645/700 [00:05<00:00, 128.73it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████▏ | 646/700 [00:05<00:00, 128.80it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████▎ | 647/700 [00:05<00:00, 128.85it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████▎ | 648/700 [00:05<00:00, 128.83it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████▎ | 649/700 [00:05<00:00, 128.90it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████▎ | 650/700 [00:05<00:00, 128.96it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████▍ | 651/700 [00:05<00:00, 129.02it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████▍ | 652/700 [00:05<00:00, 129.04it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████▍ | 653/700 [00:05<00:00, 129.11it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████▍ | 654/700 [00:05<00:00, 129.18it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████▌ | 655/700 [00:05<00:00, 129.22it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████▌ | 656/700 [00:05<00:00, 129.30it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████▌ | 657/700 [00:05<00:00, 129.35it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████▌ | 658/700 [00:05<00:00, 129.41it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████▋ | 659/700 [00:05<00:00, 129.47it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  60%|█████████████████▍           | 60/100 [00:00<00:00, 184.59it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████▋ | 660/700 [00:05<00:00, 129.48it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████▋ | 661/700 [00:05<00:00, 129.54it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████▊ | 662/700 [00:05<00:00, 129.62it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████▊ | 663/700 [00:05<00:00, 129.69it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████▊ | 664/700 [00:05<00:00, 129.76it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████▊ | 665/700 [00:05<00:00, 129.84it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████▉ | 666/700 [00:05<00:00, 129.92it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████▉ | 667/700 [00:05<00:00, 129.99it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████▉ | 668/700 [00:05<00:00, 130.04it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  96%|█████████████████████▉ | 669/700 [00:05<00:00, 130.10it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████ | 670/700 [00:05<00:00, 130.18it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████ | 671/700 [00:05<00:00, 130.24it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████ | 672/700 [00:05<00:00, 130.30it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████ | 673/700 [00:05<00:00, 130.37it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████▏| 674/700 [00:05<00:00, 130.43it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████▏| 675/700 [00:05<00:00, 130.46it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  97%|██████████████████████▏| 676/700 [00:05<00:00, 130.52it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  97%|██████████████████████▏| 677/700 [00:05<00:00, 130.59it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  97%|██████████████████████▎| 678/700 [00:05<00:00, 130.64it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  97%|██████████████████████▎| 679/700 [00:05<00:00, 130.57it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  80%|███████████████████████▏     | 80/100 [00:00<00:00, 183.50it/s]\u001b[A\n",
      "Epoch 0:  97%|██████████████████████▎| 680/700 [00:05<00:00, 130.48it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  97%|██████████████████████▍| 681/700 [00:05<00:00, 130.54it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  97%|██████████████████████▍| 682/700 [00:05<00:00, 130.59it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████▍| 683/700 [00:05<00:00, 130.63it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████▍| 684/700 [00:05<00:00, 130.68it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████▌| 685/700 [00:05<00:00, 130.73it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████▌| 686/700 [00:05<00:00, 130.78it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████▌| 687/700 [00:05<00:00, 130.84it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████▌| 688/700 [00:05<00:00, 130.89it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████▋| 689/700 [00:05<00:00, 130.94it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████▋| 690/700 [00:05<00:00, 131.00it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████▋| 691/700 [00:05<00:00, 131.06it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████▋| 692/700 [00:05<00:00, 131.11it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████▊| 693/700 [00:05<00:00, 131.17it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████▊| 694/700 [00:05<00:00, 131.23it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████▊| 695/700 [00:05<00:00, 131.28it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0:  99%|██████████████████████▊| 696/700 [00:05<00:00, 131.34it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████▉| 697/700 [00:05<00:00, 131.40it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████▉| 698/700 [00:05<00:00, 131.46it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████████████████████▋| 99/100 [00:00<00:00, 180.41it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████▉| 699/700 [00:05<00:00, 131.50it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████| 700/700 [00:05<00:00, 131.47it/s, loss=0.111, v_num=8]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▊   | 600/700 [00:04<00:00, 128.02it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                    | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▉   | 601/700 [00:04<00:00, 124.99it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▉   | 602/700 [00:04<00:00, 125.10it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▉   | 603/700 [00:04<00:00, 125.22it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  86%|██████████████████▉   | 604/700 [00:04<00:00, 125.13it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  86%|███████████████████   | 605/700 [00:04<00:00, 125.25it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  87%|███████████████████   | 606/700 [00:04<00:00, 125.36it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  87%|███████████████████   | 607/700 [00:04<00:00, 125.48it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  87%|███████████████████   | 608/700 [00:04<00:00, 125.54it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  87%|███████████████████▏  | 609/700 [00:04<00:00, 125.63it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  87%|███████████████████▏  | 610/700 [00:04<00:00, 125.71it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  87%|███████████████████▏  | 611/700 [00:04<00:00, 125.81it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  87%|███████████████████▏  | 612/700 [00:04<00:00, 125.90it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  88%|███████████████████▎  | 613/700 [00:04<00:00, 125.96it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  88%|███████████████████▎  | 614/700 [00:04<00:00, 126.04it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  88%|███████████████████▎  | 615/700 [00:04<00:00, 126.11it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  88%|███████████████████▎  | 616/700 [00:04<00:00, 126.19it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  88%|███████████████████▍  | 617/700 [00:04<00:00, 126.26it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  88%|███████████████████▍  | 618/700 [00:04<00:00, 126.35it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  88%|███████████████████▍  | 619/700 [00:04<00:00, 126.44it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  89%|███████████████████▍  | 620/700 [00:04<00:00, 126.53it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  21%|██████                       | 21/100 [00:00<00:00, 203.95it/s]\u001b[A\n",
      "Epoch 1:  89%|███████████████████▌  | 621/700 [00:04<00:00, 126.47it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  89%|███████████████████▌  | 622/700 [00:04<00:00, 126.57it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  89%|███████████████████▌  | 623/700 [00:04<00:00, 126.67it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  89%|███████████████████▌  | 624/700 [00:04<00:00, 126.76it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  89%|███████████████████▋  | 625/700 [00:04<00:00, 126.83it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  89%|███████████████████▋  | 626/700 [00:04<00:00, 126.92it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  90%|███████████████████▋  | 627/700 [00:04<00:00, 127.01it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  90%|███████████████████▋  | 628/700 [00:04<00:00, 127.08it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  90%|███████████████████▊  | 629/700 [00:04<00:00, 127.16it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  90%|███████████████████▊  | 630/700 [00:04<00:00, 127.25it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  90%|███████████████████▊  | 631/700 [00:04<00:00, 127.34it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  90%|███████████████████▊  | 632/700 [00:04<00:00, 127.41it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  90%|███████████████████▉  | 633/700 [00:04<00:00, 127.48it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▉  | 634/700 [00:04<00:00, 127.58it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▉  | 635/700 [00:04<00:00, 127.67it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  91%|███████████████████▉  | 636/700 [00:04<00:00, 127.73it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  91%|████████████████████  | 637/700 [00:04<00:00, 127.79it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  91%|████████████████████  | 638/700 [00:04<00:00, 127.87it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  91%|████████████████████  | 639/700 [00:04<00:00, 127.95it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  91%|████████████████████  | 640/700 [00:04<00:00, 128.02it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  92%|████████████████████▏ | 641/700 [00:05<00:00, 128.08it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  42%|████████████▏                | 42/100 [00:00<00:00, 202.57it/s]\u001b[A\n",
      "Epoch 1:  92%|████████████████████▏ | 642/700 [00:05<00:00, 128.14it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  92%|████████████████████▏ | 643/700 [00:05<00:00, 128.19it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  92%|████████████████████▏ | 644/700 [00:05<00:00, 128.28it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  92%|████████████████████▎ | 645/700 [00:05<00:00, 128.34it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  92%|████████████████████▎ | 646/700 [00:05<00:00, 128.42it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  92%|████████████████████▎ | 647/700 [00:05<00:00, 128.48it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  93%|████████████████████▎ | 648/700 [00:05<00:00, 128.59it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  93%|████████████████████▍ | 649/700 [00:05<00:00, 128.67it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  93%|████████████████████▍ | 650/700 [00:05<00:00, 128.74it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  93%|████████████████████▍ | 651/700 [00:05<00:00, 128.80it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  93%|████████████████████▍ | 652/700 [00:05<00:00, 128.89it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  93%|████████████████████▌ | 653/700 [00:05<00:00, 128.95it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  93%|████████████████████▌ | 654/700 [00:05<00:00, 129.00it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  94%|████████████████████▌ | 655/700 [00:05<00:00, 129.04it/s, loss=0.0728, v_num=8]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94%|████████████████████▌ | 656/700 [00:05<00:00, 129.12it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  94%|████████████████████▋ | 657/700 [00:05<00:00, 129.17it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  94%|████████████████████▋ | 658/700 [00:05<00:00, 129.22it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  94%|████████████████████▋ | 659/700 [00:05<00:00, 129.30it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  94%|████████████████████▋ | 660/700 [00:05<00:00, 129.37it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  94%|████████████████████▊ | 661/700 [00:05<00:00, 129.42it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  95%|████████████████████▊ | 662/700 [00:05<00:00, 129.48it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████████████▎          | 63/100 [00:00<00:00, 198.30it/s]\u001b[A\n",
      "Epoch 1:  95%|████████████████████▊ | 663/700 [00:05<00:00, 129.52it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  95%|████████████████████▊ | 664/700 [00:05<00:00, 129.56it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  95%|████████████████████▉ | 665/700 [00:05<00:00, 129.66it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  95%|████████████████████▉ | 666/700 [00:05<00:00, 129.72it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  95%|████████████████████▉ | 667/700 [00:05<00:00, 129.79it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  95%|████████████████████▉ | 668/700 [00:05<00:00, 129.87it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████ | 669/700 [00:05<00:00, 129.94it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████ | 670/700 [00:05<00:00, 129.98it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████ | 671/700 [00:05<00:00, 130.06it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████ | 672/700 [00:05<00:00, 130.11it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████▏| 673/700 [00:05<00:00, 130.20it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████▏| 674/700 [00:05<00:00, 130.28it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████▏| 675/700 [00:05<00:00, 130.35it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████▏| 676/700 [00:05<00:00, 130.41it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████▎| 677/700 [00:05<00:00, 130.51it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████▎| 678/700 [00:05<00:00, 130.58it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████▎| 679/700 [00:05<00:00, 130.66it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████▎| 680/700 [00:05<00:00, 130.74it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████▍| 681/700 [00:05<00:00, 130.82it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████▍| 682/700 [00:05<00:00, 130.90it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████▍| 683/700 [00:05<00:00, 130.98it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Validation DataLoader 0:  84%|████████████████████████▎    | 84/100 [00:00<00:00, 201.64it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████▍| 684/700 [00:05<00:00, 131.03it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████▌| 685/700 [00:05<00:00, 131.11it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████▌| 686/700 [00:05<00:00, 131.17it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████▌| 687/700 [00:05<00:00, 131.26it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████▌| 688/700 [00:05<00:00, 131.34it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████▋| 689/700 [00:05<00:00, 131.42it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████▋| 690/700 [00:05<00:00, 131.47it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████▋| 691/700 [00:05<00:00, 131.57it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████▋| 692/700 [00:05<00:00, 131.65it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████▊| 693/700 [00:05<00:00, 131.72it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████▊| 694/700 [00:05<00:00, 131.78it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████▊| 695/700 [00:05<00:00, 131.88it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████▊| 696/700 [00:05<00:00, 131.97it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████▉| 697/700 [00:05<00:00, 132.06it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████▉| 698/700 [00:05<00:00, 132.14it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████▉| 699/700 [00:05<00:00, 132.23it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████| 700/700 [00:05<00:00, 132.24it/s, loss=0.0728, v_num=8]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████| 700/700 [00:05<00:00, 124.09it/s, loss=0.0728, v_num=8]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model = LitNeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=num_epochs)\n",
    "trainer.fit(model, train_dataloaders=train_loader, \n",
    "            val_dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
