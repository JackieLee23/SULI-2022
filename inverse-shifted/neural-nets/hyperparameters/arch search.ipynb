{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca292432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "\n",
    "class InverseNeuralNet(pl.LightningModule):\n",
    "    def __init__(self, layer_sizes, lr = 0.01, lr_factor = 0.0):\n",
    "        super(InverseNeuralNet, self).__init__()\n",
    "        \n",
    "        modules = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            modules.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "            \n",
    "            if i != len(layer_sizes) - 2:\n",
    "                modules.append(nn.ReLU())\n",
    "        \n",
    "        self.forward_prop = nn.Sequential(*modules)\n",
    "        self.learning_rate = lr\n",
    "        self.lr_factor = lr_factor\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.forward_prop(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        dos, params = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted = self(dos)\n",
    "        loss = F.mse_loss(predicted, params)\n",
    "        \n",
    "        #log to tensorboard\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        dos, params = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted = self(dos)\n",
    "        loss = F.mse_loss(predicted, params)\n",
    "        \n",
    "        #log to tensorboard\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        if self.lr_factor == 0.0:\n",
    "            return optimizer\n",
    "        \n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "            sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=self.lr_factor, min_lr = 1e-7)\n",
    "            return {\n",
    "                \"optimizer\":optimizer,\n",
    "                \"lr_scheduler\" : {\n",
    "                    \"scheduler\" : sch,\n",
    "                    \"monitor\" : \"train_loss\",\n",
    "\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        \n",
    "        \n",
    "class InverseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dos_arr, params_arr):\n",
    "        \n",
    "        self.dos_arr = torch.from_numpy(dos_arr).float()\n",
    "        self.params_arr = torch.from_numpy(params_arr).float()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dos_arr[index], self.params_arr[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.params_arr.size(dim=0)\n",
    "    \n",
    "    \n",
    "class InverseDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_loc, batch_size):\n",
    "        super().__init__()\n",
    "        self.data = ScaledData(data_loc)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage: str = None):\n",
    "        \n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = InverseDataset(self.data.train_dos, self.data.train_params)\n",
    "            self.val_dataset = InverseDataset(self.data.val_dos, self.data.val_params)\n",
    "            \n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = DosDataset(self.data.test_dos, self.data.test_params)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.batch_size, num_workers=2)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size = self.batch_size, num_workers=2)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers=2)\n",
    "    \n",
    "\n",
    "class ScaledData:\n",
    "    def __init__(self, data_loc):\n",
    "        self.train_set = np.load(os.path.join(data_loc, 'train-set.npz'))\n",
    "        self.train_params = self.train_set['params']\n",
    "        self.train_dos_unscaled = self.train_set['dos']\n",
    "\n",
    "        self.val_set = np.load(os.path.join(data_loc, 'val-set.npz'))\n",
    "        self.val_params = self.val_set['params']\n",
    "        self.val_dos_unscaled = self.val_set['dos']\n",
    "\n",
    "        self.test_set = np.load(os.path.join(data_loc, 'test-set.npz'))\n",
    "        self.test_params = self.test_set['params']\n",
    "        self.test_dos_unscaled = self.test_set['dos']\n",
    "\n",
    "        #With standard scaling\n",
    "        scaler = StandardScaler()\n",
    "        self.train_dos = scaler.fit_transform(self.train_dos_unscaled)\n",
    "        self.val_dos = scaler.transform(self.val_dos_unscaled)\n",
    "        self.test_dos = scaler.transform(self.test_dos_unscaled)\n",
    "\n",
    "\n",
    "def plot_one(ax, mse_params, index, see_baseline):\n",
    "    ax.set_ylim([-0.5, 1.0])\n",
    "    tick_pos = np.arange(0, 3)\n",
    "    ax.plot(tick_pos, mse_params[index][2], label = \"Ground Truth\")\n",
    "    ax.plot(tick_pos, mse_params[index][1], label = \"ML Predicted\")\n",
    "    \n",
    "    if see_baseline:\n",
    "        ax.plot(tick_pos, [0, 0, 0.6], label = \"baseline\")\n",
    "    \n",
    "    ax.set_xticks(tick_pos, ('t1', 't2', 'J'))\n",
    "    ax.legend()\n",
    "\n",
    "def see_results(predicted, truth, grid_shape, percentiles, see_baseline = False):\n",
    "    mse_mat = (predicted - truth) ** 2\n",
    "    mse_list = np.mean(mse_mat, axis = 1)\n",
    "    print(f\"model mse: {np.mean(mse_list)}\")\n",
    "\n",
    "    mse_params = zip(mse_list, predicted, truth)\n",
    "    mse_params = sorted(mse_params, key = lambda x: x[0], reverse = True)\n",
    "    \n",
    "    dim1, dim2 = grid_shape\n",
    "    fig, ax = plt.subplots(dim1, dim2, figsize = (15, dim1 * 5))\n",
    "    \n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            if i * dim2 + j < len(percentiles):\n",
    "                percentile = percentiles[i * dim2 + j]\n",
    "                index = percentile * (len(mse_params)//100)\n",
    "                plot_one(ax[i][j], mse_params, index, see_baseline)\n",
    "                ax[i][j].set_title(f\"{percentile} percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9386fc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | forward_prop | Sequential | 223 K \n",
      "--------------------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n",
      "0.893     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyin/.conda/envs/ML-env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/wyin/.conda/envs/ML-env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d8870295254472bcfb9b8de29d907f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time limit reached. Elapsed time is 0:00:30. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088224a924cd4d9e8460e5d73c9bb402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss          1.9760531358770095e-05\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/project/wyin/jlee/ml-project/inverse-shifted/neural-nets/hyperparameters/val-ends/arch-search-3-test/[354, 256, 256, 256, 3],0.001,256,0.5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, datamodule\u001b[38;5;241m=\u001b[39mdos_data)\n\u001b[1;32m     87\u001b[0m end_res \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mvalidate(model, dataloaders \u001b[38;5;241m=\u001b[39m dos_data)\n\u001b[0;32m---> 88\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mval_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer_sizes\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschedule_factor\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(end_res,f)\n\u001b[1;32m     90\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/project/wyin/jlee/ml-project/inverse-shifted/neural-nets/hyperparameters/val-ends/arch-search-3-test/[354, 256, 256, 256, 3],0.001,256,0.5'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "root = \"/project/wyin/jlee/ml-project/\"\n",
    "util_loc = os.path.join(root, \"utils\")\n",
    "sys.path.append(util_loc)\n",
    "\n",
    "#########Code to make hparam iterable#################\n",
    "architectures = []\n",
    "for n_layers in range (1, 7):\n",
    "    #Uniform architecture\n",
    "    n_neurons = 8\n",
    "    while n_neurons <= 256:\n",
    "        layer_sizes = [n_neurons] * n_layers\n",
    "        n_neurons *= 2\n",
    "        architectures.append(layer_sizes)\n",
    "    \n",
    "    #Linear architecture\n",
    "    if n_layers > 1:\n",
    "        start_neurons = 32\n",
    "        while start_neurons <= 256:\n",
    "            layer_sizes = []\n",
    "            for i in range(n_layers, 0, -1):\n",
    "                layer_sizes.append(i * (start_neurons // n_layers))\n",
    "\n",
    "            start_neurons *= 2\n",
    "            architectures.append(layer_sizes)\n",
    "    \n",
    "    #Exponential architecture\n",
    "    if n_layers > 2:\n",
    "        start_neurons = 32\n",
    "        while start_neurons <= 256:\n",
    "            layer_sizes = [start_neurons]\n",
    "            for i in range(n_layers - 1):\n",
    "                layer_sizes.append(layer_sizes[len(layer_sizes) - 1] // 2)\n",
    "\n",
    "            start_neurons *= 2\n",
    "\n",
    "            architectures.append(layer_sizes)\n",
    "\n",
    "for layer_sizes in architectures:\n",
    "    layer_sizes.insert(0, 354)\n",
    "    layer_sizes.append(3)\n",
    "######################################################\n",
    "\n",
    "# step_num = int(sys.argv[1])\n",
    "# num_cpus = int(sys.argv[2])\n",
    "# torch.set_num_threads(num_cpus // 2)\n",
    "\n",
    "#######Set changed hyperparemter(s) here###############\n",
    "layer_sizes = [354, 256, 256, 256, 3]\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "schedule_factor = 0.5\n",
    "max_time = \"00:00:00:30\"\n",
    "\n",
    "data_loc = os.path.join(root, \"inverse-shifted/data\")\n",
    "save_loc = os.path.join(root, \"inverse-shifted/neural-nets/hyperparameters\")\n",
    "log_name = \"arch-search-3-test\"\n",
    "\n",
    "######################################################\n",
    "log_path = os.path.join(save_loc, \"logs\", log_name)\n",
    "val_path = os.path.join(save_loc, \"val-ends\", log_name)\n",
    "\n",
    "# if step_num == 1:\n",
    "#     os.mkdir(log_path)\n",
    "#     os.mkdir(val_path)\n",
    "#     print(\"created paths\")\n",
    "\n",
    "dos_data = InverseDataModule(data_loc, batch_size)\n",
    "logger = TensorBoardLogger(log_path, name = f'{layer_sizes},{learning_rate},{batch_size},{schedule_factor}')\n",
    "trainer = pl.Trainer(enable_checkpointing=False, max_time=max_time, logger = logger, enable_progress_bar = True)\n",
    "model = InverseNeuralNet(layer_sizes, lr = learning_rate, lr_factor = schedule_factor)\n",
    "trainer.fit(model, datamodule=dos_data)\n",
    "\n",
    "\n",
    "end_res = trainer.validate(model, dataloaders = dos_data)\n",
    "f = open(f\"{val_path}/{layer_sizes},{learning_rate},{batch_size},{schedule_factor}\",\"wb\")\n",
    "pickle.dump(end_res,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "870c33da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.0108, -0.0234,  ..., -0.0272, -0.0125,  0.0000],\n",
      "        [ 0.0000, -0.0108, -0.0234,  ..., -0.0272, -0.0125,  0.0000],\n",
      "        [ 0.0000, -0.0108, -0.0234,  ..., -0.0272, -0.0125,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0108, -0.0234,  ..., -0.0272, -0.0125,  0.0000],\n",
      "        [ 0.0000, -0.0108, -0.0234,  ..., -0.0272, -0.0125,  0.0000],\n",
      "        [ 0.0000, -0.0108, -0.0234,  ..., -0.0272, -0.0125,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(dos_data.train_dataset.dos_arr)\n",
    "\n",
    "train_dos = dos_data.train_dataset.dos_arr.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83f721c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -1.54751223e-02 -1.42881423e-02  1.38205662e-02\n",
      "  1.29438937e-03 -1.97360814e-02 -1.12810284e-02  1.74804032e-02\n",
      "  3.67304683e-03  9.30932164e-03  1.42600238e-02  6.04927540e-03\n",
      "  3.44485044e-03  1.53815150e-02  6.65807724e-03 -1.81096792e-03\n",
      "  2.04628706e-03  1.14739537e-02  3.68493795e-03  4.68838215e-03\n",
      "  2.45356560e-03 -7.77125359e-04  1.19763613e-02 -9.93967056e-03\n",
      "  3.61800194e-04  3.19242477e-03 -2.54166126e-03 -1.02458000e-02\n",
      " -8.59063864e-03 -4.79137897e-03  3.19612026e-03  1.16688013e-03\n",
      " -6.38782978e-03  5.45293093e-03 -1.41739845e-04  2.35950947e-03\n",
      " -1.60205364e-03 -4.54962254e-04  2.76446342e-04  1.84917450e-03\n",
      " -2.12824345e-03 -7.51137733e-04  4.05907631e-05 -1.52841210e-03\n",
      " -2.09450722e-04  9.28640366e-05  1.12533569e-04 -3.00616026e-04\n",
      " -6.94304705e-04 -3.27944756e-04 -8.55028629e-05  2.06828117e-05\n",
      "  2.53021717e-05  1.62124634e-05  9.06586647e-05 -9.04500484e-05\n",
      "  1.86890364e-04 -8.76188278e-05  1.34795904e-04 -1.55746937e-04\n",
      "  1.89900398e-04 -1.38580799e-04  5.25832176e-04 -2.71826982e-04\n",
      "  3.69250774e-05  2.41398811e-05 -4.87983227e-04  8.24034214e-05\n",
      "  1.29193068e-04 -4.14550304e-05 -2.50774622e-03 -1.19030476e-04\n",
      "  1.97798014e-04 -4.39882278e-04  1.79946423e-04  1.99645758e-04\n",
      "  1.58548355e-05  2.37762928e-04  3.09914351e-04 -1.55806541e-04\n",
      "  2.23219395e-05  2.03728676e-04 -5.88893890e-05  5.76674938e-05\n",
      " -2.75403261e-04  9.20891762e-05 -8.37713480e-04 -1.17182732e-04\n",
      " -7.20918179e-05 -3.31103802e-04 -3.55064869e-04 -2.21163034e-04\n",
      " -9.71555710e-06 -3.10242176e-04 -2.54943967e-04  3.30507755e-05\n",
      "  1.41620636e-04  8.23289156e-05 -1.19805336e-05 -3.06323171e-04\n",
      "  1.75192952e-04 -1.60805881e-04  4.96670604e-04  4.27365303e-05\n",
      " -9.08859074e-05 -2.57862732e-04  1.34252477e-04  3.48237809e-04\n",
      "  4.45070677e-04 -1.20047480e-04 -1.05716288e-04  3.67827713e-04\n",
      "  4.67702746e-04 -3.38882208e-04  2.19240785e-04  6.52223825e-05\n",
      " -5.09195030e-04  4.73889522e-04  3.94552946e-04 -1.73240900e-04\n",
      "  2.31742859e-04 -4.97102737e-05  1.38282776e-05  6.16312027e-05\n",
      "  4.43458557e-05  8.82148743e-06  1.68561935e-04 -2.83837318e-04\n",
      " -1.50024891e-04  2.28166580e-04  4.04715538e-04  3.61442566e-04\n",
      "  4.92244959e-04  2.54668295e-04 -3.73616815e-04  4.47362661e-04\n",
      "  1.02698803e-04 -2.23815441e-05  4.54783440e-05 -1.09124184e-03\n",
      " -6.61611557e-06  3.43501568e-04 -6.95824623e-04 -2.58505344e-04\n",
      "  2.87711620e-04  2.53081322e-04 -5.09917736e-04 -4.97102737e-04\n",
      " -2.13921070e-04  4.94182110e-04 -2.45392323e-04 -5.72204590e-05\n",
      "  9.66787338e-05  1.56939030e-04 -7.26580620e-05  9.84668732e-05\n",
      " -1.07467175e-04  3.64184380e-05  1.42455101e-04  4.08887863e-05\n",
      "  1.08480453e-04  3.28779221e-04 -2.14815140e-04 -1.96158886e-04\n",
      "  2.09063292e-04 -3.83805484e-04  2.77221203e-04 -3.24249268e-04\n",
      "  2.83360481e-04  8.04305077e-04 -8.15391541e-05 -1.52587891e-05\n",
      " -2.63452530e-04 -1.09672546e-05  4.51564789e-04  2.30789185e-04\n",
      "  1.68800354e-04 -1.55568123e-04 -1.14798546e-04 -1.85608864e-04\n",
      " -3.80516052e-04  4.05371189e-04 -2.15232372e-04 -1.33458525e-05\n",
      "  6.66975975e-05 -2.98619270e-05 -1.80959702e-04 -3.63707542e-04\n",
      " -1.23381615e-04  2.08377838e-04 -2.74181366e-05  4.51803207e-05\n",
      "  2.00390816e-04  4.22000885e-05  1.85489655e-04  3.05652618e-04\n",
      "  8.84532928e-05  3.54886055e-04  2.94446945e-04  1.18017197e-05\n",
      " -4.56571579e-04  2.22802162e-04  4.05371189e-04 -2.46047974e-04\n",
      "  5.32180071e-04 -1.88875943e-04  2.14964151e-04  2.22921371e-04\n",
      " -2.77042389e-04 -2.02655792e-05  1.19090080e-04 -1.14679337e-04\n",
      " -2.24113464e-04  1.51038170e-04 -7.62939453e-06 -3.96609306e-04\n",
      " -1.03235245e-04  2.34186649e-04  2.03907490e-04 -3.03149223e-04\n",
      " -7.26580620e-05  1.45360827e-04  6.85892999e-04  1.19373202e-04\n",
      "  4.95612621e-04 -1.25044584e-03  5.04344702e-04 -7.93099403e-04\n",
      "  7.54117966e-04  3.09944153e-04  6.61611557e-06 -8.09967518e-04\n",
      "  1.64866447e-04 -1.81674957e-04 -2.68220901e-04  1.50710344e-04\n",
      "  1.25557184e-04  8.48174095e-05  1.90660357e-05  1.45733356e-05\n",
      " -1.16616488e-04  1.24037266e-04  2.14576721e-05  1.50799751e-05\n",
      "  1.27494335e-04 -1.65700912e-05 -4.34517860e-05 -3.77297401e-05\n",
      " -2.42501497e-04  8.40425491e-06  2.88709998e-04  4.23640013e-05\n",
      " -7.90357590e-05 -9.03010368e-05 -2.65300274e-04  1.29103661e-04\n",
      " -1.04129314e-04  2.95698643e-04 -2.10165977e-04  8.70227814e-05\n",
      "  3.48091125e-04 -1.42216682e-04 -2.25424767e-04  5.31673431e-05\n",
      " -2.03251839e-05  2.87055969e-04 -7.94529915e-05 -6.16312027e-05\n",
      " -1.39355659e-04  5.76376915e-05  1.33037567e-04  1.92880630e-04\n",
      " -5.84125519e-06 -3.70144844e-05 -1.77323818e-04 -6.49690628e-06\n",
      "  2.69055367e-04  3.63469124e-04  1.45435333e-05  1.36971474e-04\n",
      " -1.18494034e-04 -2.02894211e-04  5.72204590e-05  2.37822533e-04\n",
      " -1.39713287e-04 -4.11272049e-06  2.41398811e-05 -1.59740448e-05\n",
      "  1.86622143e-04 -1.72078609e-04 -9.05990601e-06 -1.42812729e-04\n",
      "  4.76837158e-07 -1.11818314e-04 -5.12003899e-05 -1.30295753e-04\n",
      " -1.95562840e-04  1.83284283e-04  3.48091125e-05  4.44650650e-05\n",
      "  8.41021538e-05 -9.45329666e-05 -1.37925148e-04  2.24113464e-04\n",
      "  1.95026398e-04 -6.44922256e-05 -2.00927258e-04  3.83853912e-05\n",
      " -9.57846642e-05  5.37455082e-04 -2.69889832e-04 -1.97887421e-04\n",
      " -6.56366348e-04 -1.43387914e-03  5.06311655e-04 -7.74860382e-05\n",
      " -3.74466181e-04  1.58482790e-03 -1.51544809e-04  5.17952442e-03\n",
      " -1.59442425e-03 -7.65061378e-03 -6.52134418e-04  1.92165375e-03\n",
      "  8.02505016e-03  1.60491467e-03  1.16515160e-03  9.28413868e-03\n",
      " -7.22324848e-03 -2.61604786e-03  4.26769257e-04 -1.71771049e-02\n",
      " -1.02012157e-02 -9.76812840e-03 -7.98666477e-03  1.26051903e-03\n",
      "  7.40182400e-03 -6.64609671e-03  9.62889194e-03 -3.20291519e-03\n",
      " -9.12648439e-03  6.50817156e-03  1.72629356e-02  1.85963511e-03\n",
      " -3.18655372e-03  6.52933121e-03  1.47700012e-02 -7.50206411e-03\n",
      "  2.39200890e-03 -1.01495758e-02 -1.55637488e-02  1.27443094e-02\n",
      " -2.84103043e-02  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_dos, axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
