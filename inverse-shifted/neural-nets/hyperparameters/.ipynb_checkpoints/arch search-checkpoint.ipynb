{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "\n",
    "class InverseNeuralNet(pl.LightningModule):\n",
    "    def __init__(self, layer_sizes, lr = 0.01, lr_factor = 0.0):\n",
    "        super(InverseNeuralNet, self).__init__()\n",
    "        \n",
    "        modules = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            modules.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "            \n",
    "            if i != len(layer_sizes) - 2:\n",
    "                modules.append(nn.ReLU())\n",
    "        \n",
    "        self.forward_prop = nn.Sequential(*modules)\n",
    "        self.learning_rate = lr\n",
    "        self.lr_factor = lr_factor\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.forward_prop(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        dos, params = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted = self(dos)\n",
    "        loss = F.mse_loss(predicted, params)\n",
    "        \n",
    "        #log to tensorboard\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        dos, params = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted = self(dos)\n",
    "        loss = F.mse_loss(predicted, params)\n",
    "        \n",
    "        #log to tensorboard\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        if self.lr_factor == 0.0:\n",
    "            return optimizer\n",
    "        \n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "            sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=self.lr_factor, min_lr = 1e-7)\n",
    "            return {\n",
    "                \"optimizer\":optimizer,\n",
    "                \"lr_scheduler\" : {\n",
    "                    \"scheduler\" : sch,\n",
    "                    \"monitor\" : \"train_loss\",\n",
    "\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        \n",
    "        \n",
    "class InverseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dos_arr, params_arr):\n",
    "        \n",
    "        self.dos_arr = torch.from_numpy(dos_arr).float()\n",
    "        self.params_arr = torch.from_numpy(params_arr).float()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dos_arr[index], self.params_arr[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.params_arr.size(dim=0)\n",
    "    \n",
    "    \n",
    "class InverseDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_loc, batch_size):\n",
    "        super().__init__()\n",
    "        self.data_loc = data_loc\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage: str = None):\n",
    "        \n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = InverseDataset(f\"{self.data_loc}/train-set.npz\")\n",
    "            self.val_dataset = InverseDataset(f\"{self.data_loc}/val-set.npz\")\n",
    "            \n",
    "            self.mean = self.train_dataset.dos_arr.mean(0, keepdim=True)\n",
    "            self.std = self.train_dataset.dos_arr.std(0, unbiased=False, keepdim=True)\n",
    "            \n",
    "            self.train_dataset.dos_arr -= self.mean\n",
    "            self.train_dataset.dos_arr /= self.std\n",
    "\n",
    "            self.val_dataset.dos_arr -= self.mean\n",
    "            self.val_dataset.dos_arr /= self.std\n",
    "            \n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = DosDataset(f\"{self.data_loc}/test-set.npz\")\n",
    "        \n",
    "            self.test_dataset.dos_arr -= self.mean\n",
    "            self.test_dataset.dos_arr /= self.std\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.batch_size, num_workers=2)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size = self.batch_size, num_workers=2)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers=2)\n",
    "    \n",
    "\n",
    "class ScaledData:\n",
    "    def __init__(self, data_loc):\n",
    "        self.train_set = np.load(os.path.join(data_loc, 'train-set.npz'))\n",
    "        self.train_params = self.train_set['params']\n",
    "        self.train_dos_unscaled = self.train_set['dos']\n",
    "\n",
    "        self.val_set = np.load(os.path.join(data_loc, 'val-set.npz'))\n",
    "        self.val_params = self.val_set['params']\n",
    "        self.val_dos_unscaled = self.val_set['dos']\n",
    "\n",
    "        self.test_set = np.load(os.path.join(data_loc, 'test-set.npz'))\n",
    "        self.test_params = self.test_set['params']\n",
    "        self.test_dos_unscaled = self.test_set['dos']\n",
    "\n",
    "        #With standard scaling\n",
    "        scaler = StandardScaler()\n",
    "        self.train_dos = scaler.fit_transform(self.train_dos_unscaled)\n",
    "        self.val_dos = scaler.transform(self.val_dos_unscaled)\n",
    "        self.test_dos = scaler.transform(self.test_dos_unscaled)\n",
    "\n",
    "\n",
    "def plot_one(ax, mse_params, index, see_baseline):\n",
    "    ax.set_ylim([-0.5, 1.0])\n",
    "    tick_pos = np.arange(0, 3)\n",
    "    ax.plot(tick_pos, mse_params[index][2], label = \"Ground Truth\")\n",
    "    ax.plot(tick_pos, mse_params[index][1], label = \"ML Predicted\")\n",
    "    \n",
    "    if see_baseline:\n",
    "        ax.plot(tick_pos, [0, 0, 0.6], label = \"baseline\")\n",
    "    \n",
    "    ax.set_xticks(tick_pos, ('t1', 't2', 'J'))\n",
    "    ax.legend()\n",
    "\n",
    "def see_results(predicted, truth, grid_shape, percentiles, see_baseline = False):\n",
    "    mse_mat = (predicted - truth) ** 2\n",
    "    mse_list = np.mean(mse_mat, axis = 1)\n",
    "    print(f\"model mse: {np.mean(mse_list)}\")\n",
    "\n",
    "    mse_params = zip(mse_list, predicted, truth)\n",
    "    mse_params = sorted(mse_params, key = lambda x: x[0], reverse = True)\n",
    "    \n",
    "    dim1, dim2 = grid_shape\n",
    "    fig, ax = plt.subplots(dim1, dim2, figsize = (15, dim1 * 5))\n",
    "    \n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            if i * dim2 + j < len(percentiles):\n",
    "                percentile = percentiles[i * dim2 + j]\n",
    "                index = percentile * (len(mse_params)//100)\n",
    "                plot_one(ax[i][j], mse_params, index, see_baseline)\n",
    "                ax[i][j].set_title(f\"{percentile} percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399df384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /project/wyin/jlee/ml-project/inverse-shifted/neural-nets/hyperparameters/logs/arch-search-3-test/[354, 256, 256, 256, 3],0.001,256,0.5\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | forward_prop | Sequential | 223 K \n",
      "--------------------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n",
      "0.893     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024ebd821f7148eab5914221ebfbd7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time limit reached. Elapsed time is 0:00:30. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0095e0bda847dfbf6dfa13a0035763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss                    nan\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/project/wyin/jlee/ml-project/inverse-shifted/neural-nets/hyperparameters/val-ends/arch-search-3-test/[354, 256, 256, 256, 3],0.001,256,0.5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, datamodule\u001b[38;5;241m=\u001b[39mdos_data)\n\u001b[1;32m     88\u001b[0m end_res \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mvalidate(model, dataloaders \u001b[38;5;241m=\u001b[39m dos_data)\n\u001b[0;32m---> 89\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mval_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer_sizes\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschedule_factor\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(end_res,f)\n\u001b[1;32m     91\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/project/wyin/jlee/ml-project/inverse-shifted/neural-nets/hyperparameters/val-ends/arch-search-3-test/[354, 256, 256, 256, 3],0.001,256,0.5'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "root = \"/project/wyin/jlee/ml-project/\"\n",
    "util_loc = os.path.join(root, \"utils\")\n",
    "sys.path.append(util_loc)\n",
    "\n",
    "#########Code to make hparam iterable#################\n",
    "architectures = []\n",
    "for n_layers in range (1, 7):\n",
    "    #Uniform architecture\n",
    "    n_neurons = 8\n",
    "    while n_neurons <= 256:\n",
    "        layer_sizes = [n_neurons] * n_layers\n",
    "        n_neurons *= 2\n",
    "        architectures.append(layer_sizes)\n",
    "    \n",
    "    #Linear architecture\n",
    "    if n_layers > 1:\n",
    "        start_neurons = 32\n",
    "        while start_neurons <= 256:\n",
    "            layer_sizes = []\n",
    "            for i in range(n_layers, 0, -1):\n",
    "                layer_sizes.append(i * (start_neurons // n_layers))\n",
    "\n",
    "            start_neurons *= 2\n",
    "            architectures.append(layer_sizes)\n",
    "    \n",
    "    #Exponential architecture\n",
    "    if n_layers > 2:\n",
    "        start_neurons = 32\n",
    "        while start_neurons <= 256:\n",
    "            layer_sizes = [start_neurons]\n",
    "            for i in range(n_layers - 1):\n",
    "                layer_sizes.append(layer_sizes[len(layer_sizes) - 1] // 2)\n",
    "\n",
    "            start_neurons *= 2\n",
    "\n",
    "            architectures.append(layer_sizes)\n",
    "\n",
    "for layer_sizes in architectures:\n",
    "    layer_sizes.insert(0, 354)\n",
    "    layer_sizes.append(3)\n",
    "######################################################\n",
    "\n",
    "# step_num = int(sys.argv[1])\n",
    "# num_cpus = int(sys.argv[2])\n",
    "# torch.set_num_threads(num_cpus // 2)\n",
    "\n",
    "#######Set changed hyperparemter(s) here###############\n",
    "layer_sizes = [354, 256, 256, 256, 3]\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "schedule_factor = 0.5\n",
    "max_time = \"00:00:00:30\"\n",
    "\n",
    "data_loc = os.path.join(root, \"inverse-shifted/data\")\n",
    "save_loc = os.path.join(root, \"inverse-shifted/neural-nets/hyperparameters\")\n",
    "log_name = \"arch-search-3-test\"\n",
    "\n",
    "######################################################\n",
    "log_path = os.path.join(save_loc, \"logs\", log_name)\n",
    "val_path = os.path.join(save_loc, \"val-ends\", log_name)\n",
    "\n",
    "# if step_num == 1:\n",
    "#     os.mkdir(log_path)\n",
    "#     os.mkdir(val_path)\n",
    "#     print(\"created paths\")\n",
    "\n",
    "dos_data = InverseDataModule(data_loc, batch_size)\n",
    "logger = TensorBoardLogger(log_path, name = f'{layer_sizes},{learning_rate},{batch_size},{schedule_factor}')\n",
    "trainer = pl.Trainer(enable_checkpointing=False, max_time=max_time, logger = logger, enable_progress_bar = True)\n",
    "model = InverseNeuralNet(layer_sizes, lr = learning_rate, lr_factor = schedule_factor)\n",
    "trainer.fit(model, datamodule=dos_data)\n",
    "\n",
    "\n",
    "end_res = trainer.validate(model, dataloaders = dos_data)\n",
    "f = open(f\"{val_path}/{layer_sizes},{learning_rate},{batch_size},{schedule_factor}\",\"wb\")\n",
    "pickle.dump(end_res,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47643e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    nan, -0.0108, -0.0234,  ..., -0.0272, -0.0125,     nan],\n",
      "        [    nan, -0.0108, -0.0234,  ..., -0.0272, -0.0125,     nan],\n",
      "        [    nan, -0.0108, -0.0234,  ..., -0.0272, -0.0125,     nan],\n",
      "        ...,\n",
      "        [    nan, -0.0108, -0.0234,  ..., -0.0272, -0.0125,     nan],\n",
      "        [    nan, -0.0108, -0.0234,  ..., -0.0272, -0.0125,     nan],\n",
      "        [    nan, -0.0108, -0.0234,  ..., -0.0272, -0.0125,     nan]])\n"
     ]
    }
   ],
   "source": [
    "print(dos_data.train_dataset.dos_arr)\n",
    "\n",
    "train_dos = dos_data.train_dataset.dos_arr.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ff0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[            nan -1.54979927e-02 -1.42690949e-02  1.38091817e-02\n",
      "  1.40114874e-03 -1.98806673e-02 -1.12646669e-02  1.74022019e-02\n",
      "  3.66112590e-03  9.01511312e-03  1.46639049e-02  6.64719939e-03\n",
      "  3.39335203e-03  1.54001713e-02  7.31140375e-03 -1.97440386e-03\n",
      "  4.20862436e-03  1.10928416e-02  4.12374735e-03  4.81331348e-03\n",
      "  2.42340565e-03 -2.29835510e-04  1.09335184e-02 -9.85312462e-03\n",
      " -8.88109207e-05  3.14855576e-03 -3.02386284e-03  6.88731670e-03\n",
      " -7.29364157e-03 -5.85317612e-03 -6.34884834e-03 -3.32480669e-03\n",
      " -7.65550137e-03  5.15913963e-03 -2.40343809e-03  2.37303972e-03\n",
      " -3.33863497e-03  3.51369381e-03  5.08785248e-04  4.26235795e-03\n",
      " -3.20425630e-03  2.11274624e-03 -1.54483318e-03 -1.73598528e-03\n",
      "  3.46043706e-03  1.07591152e-02 -5.98663092e-03 -9.48822498e-03\n",
      " -3.90875340e-03  2.80204415e-03  1.55548453e-02  6.48376346e-03\n",
      " -8.63310695e-03 -1.19451880e-02 -1.57900751e-02  2.90045142e-03\n",
      "  9.70992446e-03 -1.05342567e-02 -5.23588061e-03  1.07551515e-02\n",
      " -8.16252828e-03 -1.12165511e-02  1.04297996e-02  5.92890382e-03\n",
      " -7.25072622e-03  4.93940711e-03 -1.12422407e-02 -1.48260593e-03\n",
      " -9.74407792e-03 -1.32773221e-02  4.37021255e-03 -8.30903649e-03\n",
      "  8.30003619e-03  1.15839243e-02  1.27854943e-03  3.80817056e-03\n",
      "  2.66346335e-03  1.04607642e-02  3.00791860e-03  2.45177746e-03\n",
      "  2.93344259e-03 -5.39994240e-03 -3.52212787e-03 -2.32300162e-03\n",
      "  6.58023357e-03  6.93127513e-03 -8.07440281e-03  6.96471334e-03\n",
      "  2.83920765e-03  4.95040417e-03  1.23115331e-02  1.10954046e-04\n",
      " -1.82847679e-03  5.09619713e-03 -3.71976197e-03 -5.27751446e-03\n",
      " -5.20211458e-03 -1.29058957e-04 -3.51125002e-03  6.29514456e-04\n",
      "  9.27582383e-04  4.20279801e-04 -1.60119683e-03  3.71608883e-03\n",
      " -3.70733067e-03 -1.64245628e-03 -2.14472366e-03 -1.06958672e-03\n",
      "  9.79633071e-04 -2.20372155e-03 -5.75508922e-04  5.53587824e-03\n",
      " -2.26744264e-03  8.84905457e-04  1.12226605e-03  4.52905893e-04\n",
      " -1.27599761e-03 -6.05292618e-04  2.57030129e-03  4.13972139e-03\n",
      "  4.01815772e-03  4.20302153e-03  4.96661663e-03  2.66408920e-03\n",
      " -1.38139725e-03 -4.37748432e-03  4.94933128e-03  2.13587284e-03\n",
      " -4.98652458e-04 -5.71608543e-04  1.36673450e-04 -2.29537487e-03\n",
      "  1.70549750e-03 -2.82365084e-03 -2.04260647e-03  1.63215399e-03\n",
      " -1.32033229e-03  1.12533569e-03 -1.04361773e-03  4.06932831e-03\n",
      "  2.55155563e-03  3.58760357e-03  6.85811043e-04 -1.87182426e-03\n",
      "  5.40113449e-03  2.20245123e-03 -1.08677149e-03 -2.44283676e-03\n",
      " -3.63999605e-03  5.95808029e-03 -2.99066305e-03 -1.02823973e-03\n",
      " -1.80727243e-03 -1.56867504e-03  1.73640251e-03 -4.67640162e-03\n",
      " -3.22967768e-03 -2.15351582e-04  1.69444084e-03  5.78445196e-03\n",
      "  1.78962946e-03 -2.15142965e-03 -1.82622671e-03 -5.68348169e-03\n",
      "  2.16087699e-03 -4.09489125e-03 -1.40154362e-03  3.95077467e-03\n",
      " -1.50537491e-03 -1.40905380e-04 -2.82144547e-03 -1.44076347e-03\n",
      "  3.31640244e-03 -3.62849236e-03 -2.38823891e-03  1.46865845e-03\n",
      " -1.10869408e-02  5.74004650e-03 -1.37865543e-03 -5.98263741e-03\n",
      "  4.54187393e-05  2.88212299e-03  8.70555639e-04  1.66918710e-03\n",
      "  9.29990411e-03  3.92019749e-03  4.18305397e-03  6.01518154e-03\n",
      "  8.49366188e-03 -3.95727158e-03 -9.02509689e-03 -5.20110130e-04\n",
      " -1.35278702e-03  1.69706345e-03 -5.59806824e-04 -3.66926193e-03\n",
      " -2.18749046e-03  4.33456898e-03  3.71217728e-03 -3.44264507e-03\n",
      "  1.00406408e-02  3.17251682e-03  6.45524263e-03  2.15381384e-03\n",
      "  6.91443682e-04  4.60186601e-03 -5.04046679e-04  2.13032961e-03\n",
      " -1.15549564e-03 -4.27162647e-03 -9.09090042e-04  3.28171253e-03\n",
      "  1.40917301e-03  1.97899342e-03 -3.51309776e-04  6.24060631e-04\n",
      "  9.24944878e-04 -3.36253643e-03  6.62028790e-04 -4.26954031e-03\n",
      "  7.94997811e-03  2.13134289e-03 -3.67799401e-03  3.19886953e-03\n",
      "  2.39558518e-03 -5.37753105e-03  9.56887007e-03 -1.07339621e-02\n",
      "  7.85303116e-03  1.10982060e-02  6.17623329e-03 -8.78566504e-03\n",
      "  3.05199623e-03 -5.49960136e-03 -3.90255451e-03 -7.09742308e-04\n",
      "  1.04438066e-02 -5.43072820e-03 -2.61394680e-03  3.01417708e-03\n",
      " -2.02310681e-02 -7.80117512e-03  8.83251429e-03 -5.84769249e-03\n",
      " -6.11960888e-04  6.80023432e-03 -9.60320234e-03 -5.57968020e-03\n",
      " -3.55517864e-03 -1.66878104e-03  3.60799208e-03 -1.87095255e-03\n",
      "  6.02647662e-03 -6.05922937e-03  8.73386860e-04  1.29060149e-02\n",
      "  1.10961199e-02  4.31442261e-03 -4.10842896e-03  7.04646111e-04\n",
      "  4.80878353e-03 -3.24916840e-03  1.90985203e-03 -1.81376934e-03\n",
      " -2.60472298e-03  7.24464655e-03 -4.83489037e-03  3.27324867e-03\n",
      " -2.59399414e-04  2.45249271e-03 -7.18533993e-04  4.78625298e-04\n",
      "  1.02347136e-03  6.31457567e-03 -2.11310387e-03 -3.63945961e-04\n",
      "  3.46088409e-03  1.35815144e-03  6.02006912e-04 -1.62088871e-03\n",
      " -3.15427780e-03 -2.12192535e-04  6.89744949e-04 -7.30514526e-04\n",
      " -3.76522541e-03  2.84337997e-03 -4.49776649e-04  1.00743771e-03\n",
      "  1.28769875e-03  2.17235088e-03 -3.60703468e-03 -1.61528587e-04\n",
      "  6.95168972e-04 -2.50387192e-03 -9.42349434e-05 -5.63859940e-05\n",
      " -2.28267908e-03  2.48116255e-03 -2.17962265e-03  2.16925144e-03\n",
      " -5.01751900e-04  7.06672668e-04 -1.29532814e-03  1.68311596e-03\n",
      "  1.05208158e-03  7.56919384e-04  1.72674656e-04  1.45262480e-03\n",
      "  9.00685787e-04  1.63704157e-03  7.31110573e-04 -2.52723694e-04\n",
      " -1.17975473e-03 -1.09350681e-03  1.11895800e-03  3.18777561e-03\n",
      " -6.61611557e-05  1.61096454e-03  6.91562891e-04  6.77603483e-03\n",
      " -1.90952420e-03 -8.54218006e-03  9.33110714e-04  1.33001804e-03\n",
      "  9.18632746e-03  2.72464752e-03  1.42562389e-03  1.06875896e-02\n",
      " -7.64977932e-03 -2.75373459e-03 -1.81078911e-04 -1.71663761e-02\n",
      " -1.01244450e-02 -1.01599693e-02 -8.33952427e-03 -8.32915306e-04\n",
      "  6.80583715e-03 -7.01636076e-03  9.94443893e-03 -3.38685513e-03\n",
      " -9.54794884e-03  6.75517321e-03  1.74527764e-02  1.86911225e-03\n",
      " -3.12742591e-03  6.39963150e-03  1.49359703e-02 -7.62222707e-03\n",
      "  2.27186084e-03 -1.00504085e-02 -1.55225694e-02  1.27431750e-02\n",
      " -2.84103043e-02             nan]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_dos, axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
